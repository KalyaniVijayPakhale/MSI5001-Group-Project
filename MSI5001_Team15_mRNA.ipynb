{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0abce442",
   "metadata": {},
   "source": [
    "# Cell 1: Markdown\n",
    "\"\"\"\n",
    "# mRNA Classification Project\n",
    "**Course:** MSI5001 - Introduction to AI  \n",
    "**Team Members:** Lisa Mithani, Shawn Lee, Aishwarya Nair, and Kalyani Vijay\n",
    "**Dataset:** mRNA Classification (Medium difficulty)  \n",
    "**Objective:** Classify RNA sequences as mRNA vs. other RNA types using machine learning models\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Data Loading & Merging\n",
    "2. Exploratory Data Analysis\n",
    "3. Feature Extraction\n",
    "4. Model Training\n",
    "5. Evaluation & Insights\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb909769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in /opt/anaconda3/lib/python3.13/site-packages (1.86)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from biopython) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbd85584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859d632",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data Loading and Preparation\n",
    "**Responsible:** Lisa Mithani\n",
    "\n",
    "## Overview\n",
    "This section loads the training and testing datasets, merges them, and prepares features and labels for modeling.\n",
    "\n",
    "## Tasks:\n",
    "1. Load training.fa (FASTA) and training.csv → merge using inner join\n",
    "2. Load testing.csv\n",
    "3. Separate features (X) and labels (y) for train/test sets\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "215f0bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training.fa...\n",
      "✓ Loaded 22867 sequences from training.fa\n",
      "\n",
      "Loading training.csv...\n",
      "✓ Loaded training.csv with shape (22867, 2)\n",
      "\n",
      "Merging datasets using inner join...\n",
      "✓ Merged training data: (14286, 4)\n",
      "  Columns: ['sequence_id', 'sequence', 'name', 'class']\n",
      "\n",
      "✓ STEP 1 COMPLETE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>name</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSDART00000138379</td>\n",
       "      <td>TCAAANGGAAAATAATATGTCAGYTGTGATTTTTACTCGANTTAAT...</td>\n",
       "      <td>ENSDART00000138379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSDART00000075994</td>\n",
       "      <td>ATGTCTCTTTTTGAAATAAAAGACCTGNTTNGAGAAGGAAGCTATG...</td>\n",
       "      <td>ENSDART00000075994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sequence_id                                           sequence  \\\n",
       "0  ENSDART00000138379  TCAAANGGAAAATAATATGTCAGYTGTGATTTTTACTCGANTTAAT...   \n",
       "1  ENSDART00000075994  ATGTCTCTTTTTGAAATAAAAGACCTGNTTNGAGAAGGAAGCTATG...   \n",
       "\n",
       "                 name  class  \n",
       "0  ENSDART00000138379      1  \n",
       "1  ENSDART00000075994      1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Load training.fa and training.csv, then merge using inner join\n",
    "# ============================================================================\n",
    "\n",
    "# Function to load FASTA file\n",
    "def load_fasta_to_dataframe(fasta_file):\n",
    "    \"\"\"\n",
    "    Reads a FASTA file and converts it to a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - fasta_file: path to .fa file\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with columns: ['sequence_id', 'sequence']\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequences.append({\n",
    "            'sequence_id': record.id,\n",
    "            'sequence': str(record.seq)\n",
    "        })\n",
    "    return pd.DataFrame(sequences)\n",
    "\n",
    "# Load training.fa (FASTA file)\n",
    "print(\"Loading training.fa...\")\n",
    "fasta_df = load_fasta_to_dataframe('dataset/training.fa')\n",
    "print(f\"✓ Loaded {fasta_df.shape[0]} sequences from training.fa\")\n",
    "\n",
    "# Load training.csv\n",
    "print(\"\\nLoading training.csv...\")\n",
    "csv_df = pd.read_csv('dataset/training_class.csv')\n",
    "print(f\"✓ Loaded training.csv with shape {csv_df.shape}\")\n",
    "\n",
    "# Merge using inner join with DIFFERENT column names\n",
    "# FASTA has 'sequence_id', CSV has 'name'\n",
    "print(\"\\nMerging datasets using inner join...\")\n",
    "training_data = pd.merge(\n",
    "    fasta_df,\n",
    "    csv_df,\n",
    "    left_on='sequence_id',   # Column in FASTA\n",
    "    right_on='name',          # Column in CSV (different name!)\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"✓ Merged training data: {training_data.shape}\")\n",
    "print(f\"  Columns: {list(training_data.columns)}\")\n",
    "print(f\"\\n✓ STEP 1 COMPLETE\")\n",
    "\n",
    "# Display first few rows\n",
    "training_data.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6fbce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing.csv...\n",
      "✓ Loaded testing.csv: (4416, 3)\n",
      "  Columns: ['name', 'sequence', 'class']\n",
      "\n",
      "✓ STEP 2 COMPLETE\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCONS_00059596</td>\n",
       "      <td>CUAAUCCCCCCUCCUCCCGCUCCCGCACCAAAGAGUUGCGCCGCCU...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TCONS_00059678</td>\n",
       "      <td>CUAUUCGGCGCAGUUGCUAUACGUACCCCAGCCUCGUACACAACGC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                           sequence  class\n",
       "0  TCONS_00059596  CUAAUCCCCCCUCCUCCCGCUCCCGCACCAAAGAGUUGCGCCGCCU...      1\n",
       "1  TCONS_00059678  CUAUUCGGCGCAGUUGCUAUACGUACCCCAGCCUCGUACACAACGC...      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Load testing.csv\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading testing.csv...\")\n",
    "testing_data = pd.read_csv('dataset/test.csv')\n",
    "\n",
    "print(f\"✓ Loaded testing.csv: {testing_data.shape}\")\n",
    "print(f\"  Columns: {list(testing_data.columns)}\")\n",
    "print(f\"\\n✓ STEP 2 COMPLETE\")\n",
    "\n",
    "testing_data.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e331e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating training data...\n",
      "✓ X_train shape: (14286, 1)\n",
      "  Columns: ['sequence']\n",
      "✓ y_train shape: (14286,)\n",
      "  Class distribution:\n",
      "class\n",
      "0    9224\n",
      "1    5062\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Separating testing data...\n",
      "✓ X_test shape: (4416, 1)\n",
      "  Columns: ['sequence']\n",
      "✓ y_test shape: (4416,)\n",
      "  Class distribution:\n",
      "class\n",
      "1    2208\n",
      "0    2208\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ STEP 3 COMPLETE\n",
      "\n",
      "⚠️ Note: X_train and X_test contain raw sequences.\n",
      "   Next step: Feature extraction (k-mer generation)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Drop class labels and store them in y_train and y_test\n",
    "# ============================================================================\n",
    "\n",
    "label_column = 'class'\n",
    "\n",
    "# --- Training Set ---\n",
    "print(\"Separating training data...\")\n",
    "y_train = training_data[label_column].copy()\n",
    "# Keep 'sequence' column for next teammate to extract features\n",
    "X_train = training_data.drop(columns=[label_column, 'sequence_id', 'name']).copy()\n",
    "\n",
    "print(f\"✓ X_train shape: {X_train.shape}\")\n",
    "print(f\"  Columns: {list(X_train.columns)}\")  # Should show ['sequence']\n",
    "print(f\"✓ y_train shape: {y_train.shape}\")\n",
    "print(f\"  Class distribution:\\n{y_train.value_counts()}\")\n",
    "\n",
    "# --- Testing Set ---\n",
    "print(\"\\nSeparating testing data...\")\n",
    "y_test = testing_data[label_column].copy()\n",
    "# Keep 'sequence' column for next teammate\n",
    "X_test = testing_data.drop(columns=[label_column, 'name']).copy()\n",
    "\n",
    "print(f\"✓ X_test shape: {X_test.shape}\")\n",
    "print(f\"  Columns: {list(X_test.columns)}\")  # Should show ['sequence']\n",
    "print(f\"✓ y_test shape: {y_test.shape}\")\n",
    "print(f\"  Class distribution:\\n{y_test.value_counts()}\")\n",
    "\n",
    "print(f\"\\n✓ STEP 3 COMPLETE\")\n",
    "print(f\"\\n⚠️ Note: X_train and X_test contain raw sequences.\")\n",
    "print(f\"   Next step: Feature extraction (k-mer generation)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5560c6b6",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1 Complete ✓\n",
    "\n",
    "**Outputs:**\n",
    "- `X_train` (14,286 samples × 1 column): Raw RNA sequences\n",
    "- `y_train` (14,286 labels): Class labels (0 or 1)\n",
    "- `X_test` (4,416 samples × 1 column): Raw RNA sequences\n",
    "- `y_test` (4,416 labels): Class labels (0 or 1)\n",
    "\n",
    "**Note for Next Teammate:**\n",
    "The `X_train` and `X_test` DataFrames contain raw RNA sequences in the `'sequence'` column. Please convert these to numeric features (e.g., k-mer frequencies) before model training.\n",
    "\n",
    "**Next Section:** Feature Extraction / Exploratory Data Analysis\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69271ee0",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Feature Extraction\n",
    "**Responsible:** [Teammate Names TBD]\n",
    "\n",
    "## Overview\n",
    "This section converts raw RNA sequences into three types of numeric features for modeling.\n",
    "\n",
    "We will extract:\n",
    "1. Character Positional Embeddings\n",
    "2. Character Tokenization\n",
    "3. K-mer Frequency Features\n",
    "\n",
    "Each feature type will be used to train separate models, then compared.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e19286",
   "metadata": {},
   "source": [
    "### Step 2.1: Character Positional Embedding\n",
    "Convert RNA sequences to positional embeddings using learned vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa3203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2.1: Character Positional Embedding - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Convert X_train['sequence'] and X_test['sequence'] to positional embeddings\n",
    "# Output: X_train_embedding, X_test_embedding (numeric DataFrames)\n",
    "\n",
    "# Example approach:\n",
    "# - Map each nucleotide (A, U, G, C) to a position index\n",
    "# - Create embedding vectors for each position\n",
    "# - Concatenate or average embeddings across sequence length\n",
    "\n",
    "print(\"⚠️ Step 2.1 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8344d21",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.2: Character Tokenization\n",
    "Tokenize sequences into character-level representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f0fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2.2: Character Tokenization - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Tokenize X_train['sequence'] and X_test['sequence']\n",
    "# Output: X_train_tokens, X_test_tokens (numeric DataFrames)\n",
    "\n",
    "# Example approach:\n",
    "# - Create vocabulary: {'A': 0, 'U': 1, 'G': 2, 'C': 3}\n",
    "# - Convert each sequence to list of token IDs\n",
    "# - Pad sequences to same length\n",
    "# - Convert to numeric array\n",
    "\n",
    "print(\"⚠️ Step 2.2 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc845ae",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.3: K-mer Feature Extraction\n",
    "Extract k-mer frequency features (k=3, 4, or 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee98fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2.3: K-mer Feature Extraction - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Extract k-mer features from X_train['sequence'] and X_test['sequence']\n",
    "# Output: X_train_kmers, X_test_kmers (numeric DataFrames)\n",
    "\n",
    "# OPTION A: Extract k-mers manually\n",
    "# - Loop through sequences and extract overlapping k-mers\n",
    "# - Count k-mer frequencies\n",
    "# - Normalize to create feature vectors\n",
    "\n",
    "# OPTION B: Load pre-computed features (FASTER)\n",
    "# X_train_kmers = pd.read_csv('dataset/train_kmer_features_k3.csv')\n",
    "\n",
    "print(\"⚠️ Step 2.3 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37012dfb",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2 Summary\n",
    "\n",
    "**Expected Outputs:**\n",
    "- `X_train_embedding` (14,286 samples × embedding_dim features)\n",
    "- `X_test_embedding` (4,416 samples × embedding_dim features)\n",
    "- `X_train_tokens` (14,286 samples × sequence_length features)\n",
    "- `X_test_tokens` (4,416 samples × sequence_length features)\n",
    "- `X_train_kmers` (14,286 samples × n_kmers features)\n",
    "- `X_test_kmers` (4,416 samples × n_kmers features)\n",
    "\n",
    "All features are now numeric and ready for class balancing.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d3a27b",
   "metadata": {},
   "source": [
    "# 3. Class Balancing\n",
    "**Responsible:** Shawn Lee\n",
    "\n",
    "## Overview\n",
    "Balance class distribution for each feature type separately.\n",
    "\n",
    "Current training class distribution:\n",
    "- Class 0: 9,224 samples (64.5%)\n",
    "- Class 1: 5,062 samples (35.5%)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cad48c",
   "metadata": {},
   "source": [
    "### Step 3.1: Balance Embedding Features\n",
    "Apply class balancing to positional embedding features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3.1: Balance Embedding Features - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Balance X_train_embedding with y_train\n",
    "# Output: X_train_embedding_balanced, y_train_balanced\n",
    "\n",
    "# Example approach using SMOTE:\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_embedding_balanced, y_train_balanced = smote.fit_resample(X_train_embedding, y_train)\n",
    "\n",
    "print(\"⚠️ Step 3.1 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d302ae2c",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3.2: Balance Token Features\n",
    "Apply class balancing to tokenization features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3.2: Balance Token Features - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Balance X_train_tokens with y_train\n",
    "# Output: X_train_tokens_balanced, y_train_balanced\n",
    "\n",
    "print(\"⚠️ Step 3.2 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22c0049",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3.3: Balance K-mer Features\n",
    "Apply class balancing to k-mer frequency features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3.3: Balance K-mer Features - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Balance X_train_kmers with y_train\n",
    "# Output: X_train_kmers_balanced, y_train_balanced\n",
    "\n",
    "print(\"⚠️ Step 3.3 incomplete - waiting for implementation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a1cf7",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3 Summary\n",
    "\n",
    "All three feature types are now balanced and ready for modeling.\n",
    "\n",
    "**Balanced Datasets:**\n",
    "- Embedding features: X_train_embedding_balanced, y_train_balanced\n",
    "- Token features: X_train_tokens_balanced, y_train_balanced\n",
    "- K-mer features: X_train_kmers_balanced, y_train_balanced\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ac189",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Model Training\n",
    "**Responsible:** [Teammate Names TBD]\n",
    "\n",
    "## Overview\n",
    "Train three separate logistic regression models using each feature type:\n",
    "1. Model A: Using Positional Embedding features\n",
    "2. Model B: Using Tokenization features\n",
    "3. Model C: Using K-mer features\n",
    "\n",
    "Each model will be evaluated independently to compare feature effectiveness.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e66fd",
   "metadata": {},
   "source": [
    "### Step 4.1: Train Logistic Regression Model A (Embedding Features)\n",
    "Train logistic regression on positional embedding features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4.1: Train Model A (Embedding Features) - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Train logistic regression on X_train_embedding_balanced\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "# model_A = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model_A.fit(X_train_embedding_balanced, y_train_balanced)\n",
    "# \n",
    "# # Predict on test set\n",
    "# y_pred_A = model_A.predict(X_test_embedding)\n",
    "#\n",
    "# Output: model_A, y_pred_A\n",
    "\n",
    "print(\"⚠️ Step 4.1 incomplete - Model A training pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f3a33",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4.2: Train Logistic Regression Model B (Token Features)\n",
    "Train logistic regression on character tokenization features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc942aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4.2: Train Model B (Token Features) - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Train logistic regression on X_train_tokens_balanced\n",
    "# model_B = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model_B.fit(X_train_tokens_balanced, y_train_balanced)\n",
    "#\n",
    "# y_pred_B = model_B.predict(X_test_tokens)\n",
    "#\n",
    "# Output: model_B, y_pred_B\n",
    "\n",
    "print(\"⚠️ Step 4.2 incomplete - Model B training pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79230cd6",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4.3: Train Logistic Regression Model C (K-mer Features)\n",
    "Train logistic regression on k-mer frequency features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e216dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 4.3: Train Model C (K-mer Features) - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Train logistic regression on X_train_kmers_balanced\n",
    "# model_C = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# model_C.fit(X_train_kmers_balanced, y_train_balanced)\n",
    "#\n",
    "# y_pred_C = model_C.predict(X_test_kmers)\n",
    "#\n",
    "# Output: model_C, y_pred_C\n",
    "\n",
    "print(\"⚠️ Step 4.3 incomplete - Model C training pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e81ee",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4 Summary\n",
    "\n",
    "**Trained Models:**\n",
    "- Model A: Logistic Regression on Embedding Features\n",
    "- Model B: Logistic Regression on Token Features\n",
    "- Model C: Logistic Regression on K-mer Features\n",
    "\n",
    "All models trained and ready for evaluation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdfb3f9",
   "metadata": {},
   "source": [
    "# 5. Classification Performance Evaluation\n",
    "**Responsible:** Shawn Lee\n",
    "\n",
    "## Overview\n",
    "Evaluate and compare the performance of all three logistic regression models.\n",
    "\n",
    "## Metrics:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- Confusion Matrix\n",
    "- ROC-AUC\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce5655",
   "metadata": {},
   "source": [
    "### Step 5.1: Evaluate All Models\n",
    "Calculate performance metrics for Models A, B, and C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d41edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5.1: Evaluate All Models - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Evaluate each model's performance\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from sklearn.metrics import classification_report, confusion_matrix\n",
    "#\n",
    "# # Evaluate Model A\n",
    "# acc_A = accuracy_score(y_test, y_pred_A)\n",
    "# precision_A = precision_score(y_test, y_pred_A)\n",
    "# recall_A = recall_score(y_test, y_pred_A)\n",
    "# f1_A = f1_score(y_test, y_pred_A)\n",
    "#\n",
    "# # Repeat for Models B and C\n",
    "#\n",
    "# # Create comparison DataFrame\n",
    "# results = pd.DataFrame({\n",
    "#     'Model': ['Model A (Embedding)', 'Model B (Tokens)', 'Model C (K-mers)'],\n",
    "#     'Accuracy': [acc_A, acc_B, acc_C],\n",
    "#     'Precision': [precision_A, precision_B, precision_C],\n",
    "#     'Recall': [recall_A, recall_B, recall_C],\n",
    "#     'F1-Score': [f1_A, f1_B, f1_C]\n",
    "# })\n",
    "#\n",
    "# print(results)\n",
    "\n",
    "print(\"⚠️ Step 5.1 incomplete - Model evaluation pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f4b56",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5.2: Compare Model Performance\n",
    "Visualize and compare performance across all models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e90705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5.2: Compare Model Performance - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Create comparison visualizations\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "#\n",
    "# # Bar chart comparing metrics\n",
    "# results.set_index('Model')[['Accuracy', 'Precision', 'Recall', 'F1-Score']].plot(kind='bar', figsize=(10,6))\n",
    "# plt.title('Model Performance Comparison')\n",
    "# plt.ylabel('Score')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "#\n",
    "# # Print confusion matrices for each model\n",
    "# print(\"Model A Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred_A))\n",
    "\n",
    "print(\"⚠️ Step 5.2 incomplete - Performance comparison pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e2c488",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5.3: Select Best Model\n",
    "Identify the best-performing model based on evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc914759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5.3: Select Best Model - TO BE COMPLETED\n",
    "# ============================================================================\n",
    "\n",
    "# TODO: Determine best model\n",
    "# best_model_idx = results['F1-Score'].idxmax()\n",
    "# best_model_name = results.loc[best_model_idx, 'Model']\n",
    "# best_f1 = results.loc[best_model_idx, 'F1-Score']\n",
    "#\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(f\"BEST MODEL: {best_model_name}\")\n",
    "# print(f\"F1-Score: {best_f1:.4f}\")\n",
    "# print(f\"{'='*60}\")\n",
    "\n",
    "print(\"⚠️ Step 5.3 incomplete - Best model selection pending\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ca87d3",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5 Summary\n",
    "\n",
    "**Performance Comparison Complete:**\n",
    "- All three models evaluated using standard classification metrics\n",
    "- Best performing model identified\n",
    "- Results ready for reporting\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a862f06c",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Advanced Model Experiments\n",
    "**Team Contributions:** Individual advanced model implementations\n",
    "\n",
    "## Overview\n",
    "After baseline logistic regression comparison, each team member explores an advanced model with custom preprocessing to maximize performance.\n",
    "\n",
    "## Team Member Assignments:\n",
    "- **Lisa:** Random Forest Classifier\n",
    "- **Shawn:** Recurrent Neural Network (RNN)\n",
    "- **Aishwarya:** Long Short-Term Memory (LSTM)\n",
    "- **Kalyani:** Transformer Model\n",
    "\n",
    "Each subsection contains: Preprocessing → Model Training → Performance Evaluation (all in one cell).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5933a00f",
   "metadata": {},
   "source": [
    "## 6.1 Random Forest Classifier\n",
    "**Responsible:** Lisa\n",
    "\n",
    "### Approach\n",
    "Use Random Forest with k-mer features and custom preprocessing.\n",
    "\n",
    "This cell contains: Additional preprocessing → Model training → Performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fe907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b189e66",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.2 Recurrent Neural Network (RNN)\n",
    "**Responsible:** Shawn\n",
    "\n",
    "### Approach\n",
    "Use RNN with sequential token features to capture sequence patterns.\n",
    "\n",
    "This cell contains: Additional preprocessing → Model training → Performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2204a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc6e8dd5",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.3 Long Short-Term Memory (LSTM)\n",
    "**Responsible:** Aishwarya\n",
    "\n",
    "### Approach\n",
    "Use LSTM to capture long-range dependencies in RNA sequences.\n",
    "\n",
    "This cell contains: Additional preprocessing → Model training → Performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4128715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c54d29e2",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.4 Transformer Model\n",
    "**Responsible:** Kalyani\n",
    "\n",
    "### Approach\n",
    "Use Transformer architecture with attention mechanism for sequence classification.\n",
    "\n",
    "This cell contains: Additional preprocessing → Model training → Performance evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cd63a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b530de5e",
   "metadata": {},
   "source": [
    "---\n",
    "## 6.5 Comprehensive Model Comparison\n",
    "Compare all models: Baseline Logistic Regression + Advanced Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f797beb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5354f29f",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6 Complete ✓\n",
    "\n",
    "**Advanced Models Implemented:**\n",
    "- ✅ Random Forest (Lisa)\n",
    "- ✅ RNN (Shawn)\n",
    "- ✅ LSTM (Aishwarya)\n",
    "- ✅ Transformer (Kalyani)\n",
    "- ✅ Comprehensive comparison of all 7 models\n",
    "\n",
    "**Key Findings:** [To be filled after implementation]\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
